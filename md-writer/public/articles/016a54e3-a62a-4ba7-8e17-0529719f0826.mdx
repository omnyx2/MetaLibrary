# testf 
  
Kubernetes에 대한 시작은 생각보다 까다롭다. 그 이유는 Kubernets를 구성하는 요소가 여러개 이며, 이들이 모여 하나의 조립식 OS 처럼 동작을 하기 때문에, K8s를 쓴다는 것은 곧 해당 구성요소를 전부 설치하고 해당 구성요소가 본인의 컴퓨터와 마찰이 없게끔 설정을 하나 하나 바꿔줘야 하기 때문이다. 

> 가장 처음에 자주 발생하는 에러는 보통아래의 요소와 관련이 깊다. 아래의 튜토리얼을 진행하면서 하나하나 다시 공부할 계획이니 아래를 하나하나 보지 말고 일단은 그런게 있구나하고 넘어가 주었으면 한다.
> 
1. 필수포트
2. ufw 프로그램
3. cgroup -systemd
4. Kubectl kubeadm kubelet의 버젼
5. CNI 
6. CRI의 socket 지정

결론적으로 쿠버네티스를 설치하기 위해서는, 설치를 시작하기도 전에, 쿠버네티스가 어떤식으로 구성되어 있고 어떤 것들이 서로 간섭을 하는지 “어느정도”(초심자의 수준)에서 알고 시작을 해야 제대로된 과정을 이해할 수 있다.

> 아, 그래서 설치가 댑다 어렵다. 클라우드 환경을 이해해야하기 때문에,
> 

# 쿠버네티스 구성요소 이해하기

쿠버네티스 환경을 이해하기 위해서는 아래의 그림을 유심히 보는 것보다 좋은 것은 없다. 아래의 요소들은 쿠버네티스를 구성하는  핵심요소들을 잘 정리해 놓은 그림이다.

![Fig.1. Kubernetes environments [1]](Kubernetes%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%8E%E1%85%B5%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5;%20Kubeadm%20d20f0d7aa37d44e696ed0baf1562b4de/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-22_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_7.39.33.png)

Fig.1. Kubernetes environments [1]

1. Control Plane
2. API server
3. Node

## Control Plane

쿠버네티스의 구성환경은 크게 위에서 언급한 3개로 나뉘게 된다. 이중에서 Kubernetes를 처음시작하는 우리가 유심히 보아야하는 것은 당연히 Control Plane이다. Control Plane은 아래의 구성요소를 포함하며 각 요소를 살짝 이해하고 넘어가는 것은 앞으로의 여정에 있어서 큰 도움을 주게될 것이다.

Control Plane은 Kubernetes를 구성하는 심장으로 아래 Control Plane의 요소에 어떤 프로그램을 설치하냐에 따라 본인이 원하는 환경을 구성할 수 있게끔 도와준다. 바로 이점이 우리가 흔히들 k8s(kubernetes와 같은말) 가 플랫폼이라고 말하는 것이며, 동시에 k8s에 엄청난 자유를 허용하게 되는데, 전통적인 OS의 관점에서 자원(램, HDD, SDD)의 확장, 네티워크의 증설 등을 관리하는 프로그램들을 회사의 환경에 맞게 조립식으로 넣는 것과 빼는 것이 가능해 지기 때문이다; 여기에서 k8s는 흔히들 조립식 OS라고 부르는 경우도 많이 있다.[1]

- **kube-apiserver:** Kubernetes에서 모든 노드 및 내 외부의 모든 프로그램이 통신을 가능하게 해주는 프로그램이다. 그리고 이 부분이 초기설치에 있어서 많은 장애를 일으기곤 한다. 보다 이부분을 능숙하게 이해하기 위해서는 네트워크와 가상네트워크에 대한 개념이 명확하게 잡혀있어야 한다.
- **etcd: 이는 kubernetes의 백업저장소로 HDD,SDD와 같은 저장소에 영구히 저장되는 영역이다.**
- **kube-scheduler: schedule를 통해서 API에 들어온 요청에 대해 워크로드 설정이나, i**ndividual and collective resource requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, and deadlines.와 같은 것들을 정하게 된다.
- **kube-controller-manager: 이는 곧 Control plane에서 돌아가는 controller로 각 컨트롤러는 한개의  프로세스로 동작하며 하나의 바이너리 파일이다. 여기에는 Node controller, Jop Contorller, Endpoint Slice controller, ServiceAccount controller가 있으며 더 많은 컨트롤러가 존재한다.**
    - 노드 컨트롤러: 노드가 다운되었을 때 통지와 대응에 관한 책임을 가진다.
    - 잡 컨트롤러: 일회성 작업을 나타내는 잡 오브젝트를 감시한 다음, 해당 작업을 완료할 때까지 동작하는 파드를 생성한다.
    - 엔드포인트슬라이스 컨트롤러: (서비스와 파드 사이의 연결고리를 제공하기 위해) 엔드포인트슬라이스(EndpointSlice) 오브젝트를 채운다
    - 서비스어카운트 컨트롤러: 새로운 네임스페이스에 대한 기본 서비스어카운트(ServiceAccount)를 생성한다.
- **cloud-controller-manager: 해당 부분은 현재로서 크게 중요하지 않다.**
    - 노드 컨트롤러: 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것
    - 라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것
    - 서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것

각각의 구성은 통신, 저장, 스케줄링, 프로세스 제어, 사용자에 의한 제어 정도로 생각을 해주면 된다. 여기서 다시 생각해보자면 이러한 것은 당연하게도 하나의 프로그램으로 구성된 것이 아니라, 여러개의 프로그램들로 구성되어 있으며 Kubernetes를 설치한다는 것은 곧 위 동작을 수행하는 프로그램들을, 본인의 니즈에 맞게, 하나하나 다 다운로드 하겠다라는 것과 동일한 의미이다.

> 그래서 어렵다. 정말로 어렵다. 하지만 우리에게는 kubeadm을 통해 쉽게 설치를할 수 있다. 고민없이,
> 

## API server와 Node

그러면 결국 이둘은 어떤 것일까? APIserver는 공교롭게도 위에서 본 Kube-apiserver가 아니다. Cloud provider API라고 하는 별도의 의미를 가지는 서버를 의미한다. 그리고 Node는 쿠버네티스가 관리하게 될 하나의 컴퓨터(자원)의 단위라고 보면 좋을 것 같다. 

조금 중요한 내용이므로 한번 더 강조를 하자면 Node는 Pod들을 소유하고 Pod 내부에는 여러개의 container들이 돌아가게 된다. 그리고, 조금있다가 설명을 하겠지만, Kubelet이라는 것은 pod에서 container가 확실하게 돌아가게 해준다.

> 다만 이걸 이해한다고 해서 사용할 수는 없다. 이는 k8s가 어떻게 구성되는지 보여주는 예시이며, 무엇을 설치해야할지에 대한 약간의 가이드를 제공해줄 뿐이기 때문이다. 우리는 이것을 어떻게 사용하는지도 알아야 이를 설치할 수가 있다.( 바로 그 사용법이 사실상 일반 개발자가 접하는 k8s이기 때문이다)
> 

## 그래서 이제 이걸 어떻게 사용하는데 ?

k8s는 control plane을 주축으로 master node, worker node를 형성하고 이를 클러스터로 구축한다. 아래의 그림을 보면, master node가 없는데 이는 master node가 control plane을 포함하여 돌리는 노드이기 때문이다. 그래서 곧 생각해보면 k8s를 돌리는데 있어서 컴퓨터는 1대 보다는 2대를 돌리는게 이상적이라는 것을 쉽게 알 수 있다. 그리고 master node를 돌리는데 있어 중요한것은 cpu가 아니라 ram의 총 크기와 클러스터 내부의 네트워크의 통신속도라는 것도.

![Fig. 2. Cluster Arhcitecture [2]](Kubernetes%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%8E%E1%85%B5%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5;%20Kubeadm%20d20f0d7aa37d44e696ed0baf1562b4de/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-07-22_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_8.04.50.png)

Fig. 2. Cluster Arhcitecture [2]

결국 쿠버네티스를 설치한다는 것의 위의 요소를 적절하게 배치할 수 있도록 플랫폼을 설계하고 구성하는 것이며, 이에 맞게 필요한 프로그램들을 설치하여, 하나의 조립식 OS를 만들어 서비스를 유저에게 “죽지않고 제대로 잘” 배포하기 위한 전용 컴퓨터를 만들어, 여러대의 컴퓨터를 마치 하나처럼 쓰겠다는 것과 같은 의미이다.

이를 위해 우리는 

1. Etcd, Scheduler, kube-controller-manager, cloud-control-manager, kube-api-server.
2. kublet, kube-proxy
3. pod(CRI)

를 설치할 계힉이다.

> 너무 어려워서 겁을 먹었는가? 걱정마라 설치는 생각보다 쉬우니까.
> 

# Kubernetes를 설치한다는 것,

위의 장황한 설명과는 다르게 Kubernetes를 설치한다는 것은 생각보다 어렵지 않다. 그러면 왜 이렇게 어렵게 설명을 했을까? K8s를 그냥 설치하는 것은 생각보다 그렇게 중요한 내용이 아님을, 그리고 그 절차가 어려워도 어쩔 수 없으니 감당하라는 의미를 전하고 싶었다. 그래도 우리가 직접 이를 전부 만드는 것보다야 낫지 않은가, 그리고 결국 k8s를 잘 사용하기 위해서는 각 설치과정이 어떤의미를 지닌지 정확히 파악하고 이를 이해해야 추후 다른 배포환경, 확장, 축소와 같은 행위를 할 때 보다 본인 스스로가 어떤 과정을 밟고 있는지 쉽게 이해가 될 것이다.

그래서 다시 돌아와 kubernetes를 설치한다는 것은 아래의 요소를 마스터노드와 워커노드에 적절히 설치 및 설정을 적용헤 해주는 것이다.

- kubectl: kubenetes를 쉽게 제어하기 위한 CLI명령어 모음
- k8s(Etcd, Scheduler, kube-controller-manager, cloud-control-manager, kube-api-server, kube-proxy, cri): k8s의 마스터 노드를 구성에 필요한 프로그램들
- kubelet: Node들이 돌아가기 위한
- kuberenetes 설정파일: 이것을 우리가 프로그램 하여 개발 및 배포 환경을 구성해 줄 수 있다. 하지만 초기 학습 및 구성 단계에서는 이를 명령어 및 수동으로 직접적으로 제어해주어야 한다.
- add - on

위의 요소를 4개로 분리한 까닭은 각각이 설치 되는 이유와 범위가 다르기 때문이다. Kubectl은 kubenetes의 사용을 도와주는 툴이고 k8s는 마스터 노드를 구성하여(조립식OS)를 돌리기 위해 설치해야하며, kubelet은 work node를 만들기 위해서 필요한 툴이기 때문이다. 그리고 이를 현재 본인의 컴퓨터의 환경과 충돌하지 않고 돌리기 위한 설정 구성까지로 하여 총 4단계로 구성을 잡아 나누었다.

add - on 은 플러그인으로 기능확장에 사용한다.

> 결국 우리가 설치해야할 것은 kubectl, k8s(bootstrap), kubelet을 마스터와 워커에 설치하고 각 프로그램들이 원활히 돌아갈 수 있도록 충돌 및 시스템 환경 구성요소를 잘 잡아주면된다.
> 

### CRI란 ?

CRI란  container runtime interface의 약자로 pod가 실행시킬 container프로그램의 인터페이스이다. 따라서 k8s의 설치 이전에 설치가 되어야 하며, 고수준 CRI, 저수준 CRI를 전부 설치해 주어야한다. 아래는 CRI의 종류이며 우리는 Containerd와 Cri-O, runc를 설치할 계획이다.

- Containerd
- Cri-O
- PodMan
- runc(저수준)

이에 대해서는 좋은 레퍼런스가 있어 첨부하며, 반드시 잘 읽어볼 것을 추천한다.

# Kubernetes설치; kubeadm을 중심으로

이제부터 kubernetes를 설치할 것이며 아래의 절차를 거쳐 마스터노드와 워커 노드를 구성하고 설치할 계획이다.

## 전체적인 설치 및 설정 순서

---

마스터 노드 구성하기, 위의 내용을 잘 이해했다면 1,5,6은 사실 1,2,3, 순서로 진행해도  문제가  크게 없으며 그 외에도 여기에 기입 된 핵심적인 순서인: CRI 설치 & kubectl 셋팅 및 설치 → cgroup driver 팅 & 네트워크 포트 셋팅 → kubelet 셋팅 & kubeadm 설치 → kubeadm 셋팅의 순서만 지킨다면 하위의 셋팅 순서는 변경되어도 크게 문제가 없음을 쉽게 알 수 있다.

1. 메모리 스왑영역 꺼주기(에러 가능성 존재, 클러스터 데이터 교환간 방해)
2. kubernetes설치 파일이 위치한 레포지토리 apt에 등록하기 (구글이 별도의 레포에서 관리함)
3. kubectl 설치 
4. kubectl 자동완성 기능 설치(optional)
5. 고수준 및 저수준의 CRI의 설치(저수준은 docker.io로 자동 설치된다)
6. CRI에서 사용하는 cgroup 변경 및 정의(kube는 systemd를 사용하나 Containerd의 경우 systemd를 기본으로 사용하지 않는다. cgroup driver에서는 systemd와 cgroupf가 있는데 둘이 명령어가 호환되지 않기 때문이다.)
7. k8s설치전 CRI에서 CRI간 네트워크 라우팅 허용하기 (iptables의 셋팅 변경을 해줘야함)
    1. 기본적으로, 리눅스 커널은 IPv4 패킷을 인터페이스 간에 라우팅하는 것을 허용하지 않기 때문이다.
    2. inter-vlan([https://12bme.tistory.com/356](https://12bme.tistory.com/356), [https://daengsik.tistory.com/43](https://daengsik.tistory.com/43))
8. CRI 재시작 및 시작마다 켜지게 등록
9. kubeadm의 control plane이 내부적으로 통신할 네트워크 포트 열어주기 - 6개의 내부 프로그램을 사용하므로 6개면 충분함.
10. kubeadm 설치에 필요한 둘 설치하기 (ssl<통신암호화, 자격증명>, https api<통신형성>, gpg<암호화 및 서명>
11. kubeadm다운로드를 위한 api키 셋팅 및 다운하기
12. kubeadm, kubectl, kubelet내부 프로그램간 버젼 맞추기
13. k8s bootstrap다운하기(설치 자동)
14. 설치 이후에 명령어 붙여 넣기
15. CNI 설치 및 Flannel add-on설치하기(Default CNI는 여러 노드를 클러스터로 둘 수 없기 때문이다.)
16. kudeadm 초기 셋팅을 통해 control plane 구성하기(마스터 노드 생성)
17. 마스터 노드 설치상태 점검 및 토큰, hash값 찾아내고 워커노드에 넣을 준비를 한다.

---

 워커노드 구성하기, 워커노드의 경우도 마찬가지로 CRI,와 kubelet, kubeproxy만 설치하면 돌아감을 알 수 있으나, 우리의 경우 kubeadm을 이용해 쉽게 join을 구현할 계획이므로 kubeadm을 위한 셋팅과 설치를 해주면 된다.

1. worker node설치하기 위의 절차중 CRI 및 9~12, 그리고 내부 라우팅 관련 설정을 풀어준다.(kubetelt, kubeproxy를 위해서)
2. Master node에  join넣기
3. 클러스터 형성 확인하기

---

# 설치 따라하기

자 이제 설치 순서에 대해서 배웠으니 설치를 쉽게 따라 할 수 있도록 스텝을 제공해주고자 한다. 설치과정을 이해하는 것은 곧 k8s가 어떤철학으로 만들어지고 어떤 커스텀을 할 수 있는지 한눈에 알 수 있게 해준다는 관점에서 정말로 중요하게 생각하여 다루었고 실제로 이를 설치하는 것은 그렇게 어렵지 않고 쉽게 진행할 수 있다. 그리고 보다 쉽게 셋팅을 적용하기 위해서 관리자 모드로 진입하여 진행하도록 한다.

kubectl 셋팅 & 설치

```bash
sudo apt-get update
# apt-transport-https may be a dummy package; if so, you can skip that package
sudo apt-get install -y apt-transport-https ca-certificates curl gnupg

# If the folder `/etc/apt/keyrings` does not exist, it should be created before the curl command, read the note below.
# sudo mkdir -p -m 755 /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
sudo chmod 644 /etc/apt/keyrings/kubernetes-apt-keyring.gpg # allow unprivileged APT programs to read this keyrin
# This overwrites any existing configuration in /etc/apt/sources.list.d/kubernetes.list
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo chmod 644 /etc/apt/sources.list.d/kubernetes.list   # helps tools such as command-not-found to work correctly
sudo apt-get update
sudo apt-get install -y kubectl
```

Cri-O 설치 -  공식 깃허브 레퍼런스 참조 2024.07.23 기준

```bash
sudo apt-get update
sudo apt-get install -y software-properties-common curl
sudo curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/Release.key |
    gpg --dearmor -o /etc/apt/keyrings/cri-o-apt-keyring.gpg

sudo echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/ /" |
    tee /etc/apt/sources.list.d/cri-o.list

sudo apt-get update
sudo apt-get install -y cri-o

```

Contianerd & runc 설치

```bash
sudo apt install docker.io
```

다만 contianerd의 cgroup을 변경해 주어야 한다. To use the `systemd` cgroup driver in `/etc/containerd/config.toml` with `runc`, set

```bash
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  ...
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
    SystemdCgroup = true
```

컨테이너간 내부 iptable 내부 라우팅 허용하기

```bash
# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system
```

```bash
sudo systemctl restart containerd
sudo systemctl start crio.service
sudo systemctl restart containerd
```

Kubeadm, kubelet 설치전 셋팅하기(필수 포트 개방, 스왑끄기), 아래 종류 참고하여 netcat으로 종료 권장 

[https://kubernetes.io/docs/reference/networking/ports-and-protocols/](https://kubernetes.io/docs/reference/networking/ports-and-protocols/)

```bash
sudo apt install net-tools
ufw allow 
```

### 메모리 스왑영역 꺼주기(에러 가능성 존재, 클러스터 데이터 교환간 방해)

```bash
swapoff -a 
```

### 

```bash

```

### Cri-O의 설치

Cri의 의존성 설치 및 레포를 등록하고 cri-o를 설치한다.

```bash
sudo su 

apt-get update
apt-get install -y software-properties-common curl

curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/Release.key | 
gpg --dearmor -o /etc/apt/keyrings/cri-o-apt-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/ /" |
    tee /etc/apt/sources.list.d/cri-o.list
    
apt-get update
apt-get install -y cri-o 
```

cri-o의 croup-driver를 systemd로 변경한다. CRI-O uses the systemd cgroup driver per default, which is likely to work fine for you. To switch to the `cgroupfs`cgroup driver, either edit `/etc/crio/crio.conf` or place a drop-in configuration in `/etc/crio/crio.conf.d/02-cgroup-manager.conf`, for example:

```bash
[crio.runtime]
conmon_cgroup = "pod"
cgroup_manager = "cgroupfs"
```

# Kubeadm, minikube, kops

k8s의 설치는 생각보다 복잡하다. 많은 사람들이 그렇게 느꼈고 이를 위해 bootstrap을 만들어 배포하게 된다. kubeadm, minikube, kops 전부 이러한 bootstrap 프로그램이다. 우리는 그중에서 프로덕션 환경과 가장 비슷하게 있는 kubeadm을 이용해 클러스터를 구성할 계획이다.

전체적인 설치는 공식 문서에서 제공하는 설치순서를 따를 계획이다.

1. kubectl 설치
2. CRI 설치
3. kubeadm 설치

---

주의사항

- 쿠버네티스는 pod를 만들지 CRI를 만들지 않는다. POD만을 관리하고 띄울 뿐,, 따라서 컴퓨터와 저장에 관련된 모든 리소스는 contianer에서 잘 설정을 먹여줘야한다.

[1] Kubernetes Official, “**Kubernetes Components,” Kubernetes., July. 2024, Avaliable:** [https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/)

[2] Kubernetes Official, "Cluster Arhcitecture,” Kubernetes., Oct. 2023, Avaliable: [https://kubernetes.io/docs/concepts/architecture/](https://kubernetes.io/docs/concepts/architecture/)